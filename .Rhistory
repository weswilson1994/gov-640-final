plot(full_model_selection, scale = "adjr2")
for (i in 1:n_variables) {
coefi_train <- coef(reg_subsets_train, id = i)
pred_train <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((training_data$n_gibill - pred)^ 2))
}
nrow(reg_subsets_train)
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18)
rmse_for_models_train <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi_train <- coef(reg_subsets_train, id = i)
pred_train <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((training_data$n_gibill - pred)^ 2))
}
full_model_matrix_train <- model.matrix(full_model_formula, data = training_data)
for (i in 1:n_variables) {
coefi_train <- coef(reg_subsets_train, id = i)
pred_train <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((training_data$n_gibill - pred)^ 2))
}
rmse_for_models_train <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi_train <- coef(reg_subsets_train, id = i)
pred_train <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((training_data$n_gibill - pred)^ 2))
}
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
rmse_for_models_train <- rep(NA, n_variables)
est_data
test_data
test_data$n_gibill
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
rmse_for_models_train
rmse_for_models_train - rmse_for_models
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18, method = "backward")
plot(reg_subsets_train, scale = "bic")
# Create a model matrix to build an "X" matrix from the test data.
full_model_matrix <- model.matrix(full_model_formula, data = test_data)
n_variables <- full_model_selection$last - 1 # remove the intercept as a variable.
rmse_for_models <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
which.min(mse_for_models)
coef(reg_subsets_train, which.min(mse_for_models)) # this model has the lowest RMSE
tibble(rmse_for_models = mse_for_models,
n_var = 1:n_variables,
var_names = coef(reg_subsets_train, n_var)) %>%
arrange(rmse_for_models)
# looking at the resulting RMSE, the appears to be very little variation in my estimates.
# for completeness, I am going to check the RMSE on the training data to see how they change.
full_model_matrix_train <- model.matrix(full_model_formula, data = training_data)
n_variables <- full_model_selection$last - 1 # remove the intercept as a variable.
rmse_for_models_train <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
plot(full_model_selection, scale = "bic")
library(MASS)
stepAIC(full_model_formula, direction = "backward")
stepAIC(full_model_formula, direction = "backward", model_data)
full_model <- lm(full_model_formula, data = model_data)
summary(full_model)
options(scipen = 999)
summary(full_model)
stepAIC(full_model, direction = "backward")
full_model <- lm(full_model_formula, data = training_data)
n_variables <- full_model_selection$last - 1 # remove the intercept as a variable.
rmse_for_models <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
which.min(mse_for_models)
coef(reg_subsets_train, which.min(mse_for_models)) # this model has the lowest RMSE
tibble(rmse_for_models = mse_for_models,
n_var = 1:n_variables,
var_names = coef(reg_subsets_train, n_var)) %>%
arrange(rmse_for_models)
# looking at the resulting RMSE, the appears to be very little variation in my estimates.
# for completeness, I am going to check the RMSE on the training data to see how they change.
full_model_matrix_train <- model.matrix(full_model_formula, data = training_data)
n_variables <- full_model_selection$last - 1 # remove the intercept as a variable.
rmse_for_models_train <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
rmse_for_models_train - rmse_for_models
stepAIC(full_model, direction = "backward")
summary(full_model)
plot(full_model)
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
View(gi_bill)
gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon))
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment)  %>%
na.omit()
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment)
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
na.omit()
# Limiting down to only the variables I am interested in for my analysis.
gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
na.omit()
# Limiting down to only the variables I am interested in for my analysis.
gi_bill %>%
select(bah) %>%
na.omit()
# Limiting down to only the variables I am interested in for my analysis.
gi_bill %>%
select(bah)
#------------------------------------------------------------------------- Data
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
#------------------------------------------------------------------------- Packages
library(tidyverse)
library(leaps)
library(MASS)
options(scipen = 999)
#------------------------------------------------------------------------- Data
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
# Limiting down to only the variables I am interested in for my analysis.
model_data <- gi_bill %>%
select(bah:avg_yellow_ribbon_payment) %>%
select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
gi_bill %>%
select(bah:avg_yellow_ribbon_payment)
gi_bill %>%
select(n_gibill)
gi_bill %>%
dplyr::select(n_gibill)
model_data <- gi_bill %>%
dplyr::select(bah:avg_yellow_ribbon_payment) %>%
dplyr::select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
full_model_formula <- n_gibill ~ . + yr_member:avg_yellow_ribbon_payment + yr_member:annual_tuition
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
model_data <- gi_bill %>%
dplyr::select(bah:avg_yellow_ribbon_payment) %>%
dplyr::select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
# Static values
split_percentage <- .70
full_model_formula <- n_gibill ~ . + yr_member:avg_yellow_ribbon_payment + yr_member:annual_tuition
set.seed(123)
train_index <- sample(nrow(model_data), split_percentage * nrow(model_data))
training_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18, method = "backward")
plot(reg_subsets_train, scale = "bic")
full_model <- lm(full_model_formula, data = training_data)
summary(full_model)
plot(full_model)
n_variables <- full_model_selection$last - 1 # remove the intercept as a variable.
n_variables <- reg_subsets_train$last - 1 # remove the intercept as a variable.
rmse_for_models <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
# Create a model matrix to build an "X" matrix from the test data.
full_model_matrix <- model.matrix(full_model_formula, data = test_data)
n_variables <- reg_subsets_train$last - 1 # remove the intercept as a variable.
rmse_for_models <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
which.min(mse_for_models)
which.min(rmse_for_models)
coef(reg_subsets_train, which.min(rmse_for_models)) # this model has the lowest RMSE
tibble(rmse_for_models = rmse_for_models,
n_var = 1:n_variables,
var_names = coef(reg_subsets_train, n_var)) %>%
arrange(rmse_for_models)
full_model_matrix_train <- model.matrix(full_model_formula, data = training_data)
n_variables <- full_model_selection$last - 1 # remove the intercept as a variable.
full_model_matrix_train <- model.matrix(full_model_formula, data = training_data)
n_variables <- reg_subsets_train$last - 1 # remove the intercept as a variable.
rmse_for_models_train <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((test_data$n_gibill - pred)^ 2))
}
rmse_for_models_train - rmse_for_models # the rmse decreases when going from the training to test data, which is ideal.
stepAIC(full_model, direction = "backward")
which.min(rmse_for_models_train)
coef(reg_subsets_train, which.min(rmse_for_models))
coef(reg_subsets_train, which.min(rmse_for_models))
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18, method = "backward")
plot(reg_subsets_train, scale = "bic")
full_model <- lm(full_model_formula, data = model_data)
summary(full_model)
# I will need some transformation or standardization.
plot(full_model)
plot(reg_subsets_train, scale = "bic")
stepAIC(full_model, direction = "backward")
final_model <- lm(formula = n_gibill ~ undergrad_enrollment + yr_member + poe_member + dodmou + student_vet_grp_ipeds + annual_tuition + n_vets_census + yr_member:annual_tuition, data = model_data)
summary(final_model)
selected_model <- lm(formula = n_gibill ~ undergrad_enrollment + yr_member + poe_member + dodmou + student_vet_grp_ipeds + annual_tuition + n_vets_census + yr_member:annual_tuition, data = model_data)
summary(selected_model)
plot(selected_model)
lm(formula = n_gibill ~ log(undergrad_enrollment) + yr_member + poe_member + dodmou + student_vet_grp_ipeds + annual_tuition + n_vets_census + yr_member:annual_tuition, data = model_data)
lm(formula = n_gibill ~ log(undergrad_enrollment) + yr_member + poe_member + dodmou + student_vet_grp_ipeds + annual_tuition + n_vets_census + yr_member:annual_tuition, data = model_data) %>%
plot()
lm(formula = n_gibill ~ log(undergrad_enrollment) + yr_member + poe_member + dodmou + student_vet_grp_ipeds + log(annual_tuition) + n_vets_census + yr_member:annual_tuition, data = model_data) %>%
plot()
lm(formula = n_gibill ~ sqrt(undergrad_enrollment) + yr_member + poe_member + dodmou + student_vet_grp_ipeds + annual_tuition + n_vets_census + yr_member:annual_tuition, data = model_data) %>%
plot()
lm(formula = n_gibill ~ undergrad_enrollment^3 + yr_member + poe_member + dodmou + student_vet_grp_ipeds + annual_tuition + n_vets_census + yr_member:annual_tuition, data = model_data) %>%
plot()
mean(selected_model$residuals)
mean(sqrt(selected_model$residuals))
ggplot(data = selected_model$residuals, aes(x = selected_model$residuals)) +
geom_bar()
scale(model_data[ , "undergrad_enrollment", "tuition"])
enrollment_mean <- mean(model_data$undergrad_enrollment)
enrollment_sd <- sd(model_data$undergrad_enrollment)
model_data %>%
mutate(undergrad_enrollment = (undergrad_enrollment - enrollment_mean) /
enrollment_sd)
model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = TRUE))
model_data %>%
mutate(undergrad_enrollment = (undergrad_enrollment - enrollment_mean) /
enrollment_sd)
model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = TRUE))
model_data %>%
mutate(undergrad_enrollment = (undergrad_enrollment - enrollment_mean) /
enrollment_sd)
model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE))
model_data <- model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE))
set.seed(123)
train_index <- sample(nrow(model_data), split_percentage * nrow(model_data))
training_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18, method = "backward")
plot(reg_subsets_train, scale = "bic")
full_model <- lm(full_model_formula, data = model_data)
summary(full_model)
# I will need some transformation or standardization.
plot(full_model)
model_data <- model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE)) %>%
mutate(n_gibill = scale(n_gibill, scale = TRUE)
)
set.seed(123)
train_index <- sample(nrow(model_data), split_percentage * nrow(model_data))
training_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18, method = "backward")
plot(reg_subsets_train, scale = "bic")
full_model <- lm(full_model_formula, data = model_data)
summary(full_model)
# I will need some transformation or standardization.
plot(full_model)
model_data <- model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE))
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
model_data <- gi_bill %>%
dplyr::select(bah:avg_yellow_ribbon_payment) %>%
dplyr::select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
# Static values
split_percentage <- .70
full_model_formula <- log(n_gibill) ~ . + yr_member:avg_yellow_ribbon_payment + yr_member:annual_tuition
enrollment_mean <- mean(model_data$undergrad_enrollment)
enrollment_sd <- sd(model_data$undergrad_enrollment)
model_data <- model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE))
set.seed(123)
train_index <- sample(nrow(model_data), split_percentage * nrow(model_data))
training_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 18, method = "backward")
# I will need some transformation or standardization.
plot(full_model)
model_data <- model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE))
View(model_data)
model_data <- gi_bill %>%
dplyr::select(bah:avg_yellow_ribbon_payment) %>%
dplyr::select(! c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
model_data <- model_data %>%
mutate(undergrad_enrollment = scale(undergrad_enrollment, scale = T)) %>%
mutate(annual_tuition = scale(annual_tuition, scale = TRUE))
View(model_data)
names(model_data)
# Static values
split_percentage <- .70
full_model_formula <- n_gibill ~ . + yr_member:avg_yellow_ribbon_payment + yr_member:annual_tuition
enrollment_mean <- mean(model_data$undergrad_enrollment)
enrollment_sd <- sd(model_data$undergrad_enrollment)
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
gi_bill <- read_rds(file = "./data/final/final_gi_bill_data_for_analysis.rds")
# Load Packages -----------------------------------------------------------
library(tidyverse)
library(leaps)
library(MASS)
library(corrplot)
library(car)
library(gtsummary)
library(gt)
library(webshot2)
options(scipen = 999)
# Read in the Data --------------------------------------------------------
gi_bill <- read_rds(file = "../data/final/final_gi_bill_data_for_analysis.rds")
# Read in the Data --------------------------------------------------------
gi_bill <- read_rds(file = "../data/final/final_gi_bill_data_for_analysis.rds")
getwd()
# Read in the Data --------------------------------------------------------
gi_bill <- read_rds(file = "data/final/final_gi_bill_data_for_analysis.rds")
# Load Packages -----------------------------------------------------------
library(tidyverse)
library(leaps)
library(MASS)
library(corrplot)
library(car)
library(gtsummary)
library(gt)
library(webshot2)
options(scipen = 999)
# Read in the Data --------------------------------------------------------
gi_bill <- read_rds(file = "data/final/final_gi_bill_data_for_analysis.rds")
# Load Static Values ------------------------------------------------------
n_gi_tool <- nrow(read_rds(file = "../data/original/gi_bill_comparison_tool.rds"))
# Load Packages -----------------------------------------------------------
library(tidyverse)
library(leaps)
library(MASS)
library(corrplot)
library(car)
library(gtsummary)
library(gt)
library(webshot2)
options(scipen = 999)
# Read in the Data --------------------------------------------------------
gi_bill <- read_rds(file = "data/final/final_gi_bill_data_for_analysis.rds")
# Load Static Values ------------------------------------------------------
n_gi_tool <- nrow(read_rds(file = "data/original/gi_bill_comparison_tool.rds"))
n_census <- nrow(read_rds(file = "data/original/vets_acs_survey_by_zip_code.rds"))
split_percentage <- .70
gi_max <- 27120
# Prepare Modeling Data -------------------------------------------
model_data <- gi_bill %>%
dplyr::select(bah:avg_yellow_ribbon_payment, institution) %>%
dplyr::select(!c(p911_recipients, p911_yr_recipients, p911_tuition_fees, p911_yellow_ribbon)) %>%
na.omit()
model_data <- model_data %>%
filter(n_gibill != 0) %>%
mutate(avg_yellow_ribbon_payment = avg_yellow_ribbon_payment) %>%
mutate(avg_yellow_ribbon_payment = if_else(avg_yellow_ribbon_payment == 0, .0000001, avg_yellow_ribbon_payment))
# Model Selection ---------------------------------------------------------
full_model_formula <- log(n_gibill) ~ bah + log(undergrad_enrollment) + log(avg_yellow_ribbon_payment) + log(annual_tuition) +
yr_member + poe_member + eight_keys_member + dodmou +
credit_for_mil_training + vet_poc + student_vet_grp_ipeds +
graduation_rate_all_students + retention_all_students_ba +
salary_all_students + n_vets_census
full_model <- lm(full_model_formula, data = model_data)
summary(full_model)
## Exploratory Analysis ----------------------------------------------------
plot(full_model)
### Cross Validation -- For Exploratory Purposes ----------------------------
set.seed(123)
train_index <- sample(nrow(model_data), split_percentage * nrow(model_data))
training_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
# Sub-setting model variables using backward selection.
reg_subsets_train <- regsubsets(full_model_formula, data = training_data, nvmax = 20, method = "backward")
## Exploring the plot functions from the leap packages
plot(reg_subsets_train, scale = "adjr2")
### Creating a model matrix to use for testing from the test data.
full_model_matrix <- model.matrix(full_model_formula, data = test_data)
# I am going to compare RMSE for training and test data for a bunch of different models to try and select the best model. So, I will
# Run a for-loop for each variable;
## Extract the coefficients from the regsubsets used on my training data earlier;
## Multiply them into the appropriate columns;
### Compute the test MSE.
n_variables <- reg_subsets_train$last - 1 # remove the intercept as a variable.
rmse_for_models <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix[, names(coefi)] %*% coefi
rmse_for_models[i] <- sqrt(mean((test_data$n_gibill - pred)^2))
}
# Which model did the best?
which.min(rmse_for_models)
coef(reg_subsets_train, which.min(rmse_for_models)) # this model has the lowest RMSE
tibble(
rmse_for_models = rmse_for_models,
n_var = 1:n_variables,
var_names = coef(reg_subsets_train, n_var)
) %>%
arrange(rmse_for_models)
### For completeness, I am going to check the RMSE on the training data to see how they change.
full_model_matrix_train <- model.matrix(full_model_formula, data = training_data)
n_variables <- reg_subsets_train$last - 1 # remove the intercept as a variable.
rmse_for_models_train <- rep(NA, n_variables)
for (i in 1:n_variables) {
coefi <- coef(reg_subsets_train, id = i)
pred <- full_model_matrix_train[, names(coefi)] %*% coefi
rmse_for_models_train[i] <- sqrt(mean((test_data$n_gibill - pred)^2))
}
which.min(rmse_for_models_train)
coef(reg_subsets_train, which.min(rmse_for_models_train))
## Stepwise Variable Selection ---------------------------------------------
stepAIC(object = full_model, direction = "both")
selected_model <- lm(formula = log(n_gibill) ~ log(undergrad_enrollment) +
log(avg_yellow_ribbon_payment) + log(annual_tuition) + poe_member +
dodmou + credit_for_mil_training + student_vet_grp_ipeds + log(salary_all_students) +
n_vets_census, data = model_data)
summary(selected_model)
# Model Diagnostics -------------------------------------------------------
plot(selected_model)
# Check for multicollinearity ---------------------------------------------
## Correlation matrix
corr_matrix <- model_data %>%
dplyr::select(-institution) %>%
cor()
corrplot(corr_matrix)
## Variance Inflation Factor (VIF)
vif(selected_model)
# Identify Outliers -------------------------------------------------------
## Identify residuals that have a standard deviation above three.
potential_outliers <- tibble(
standardized_residuals = scale(selected_model$residuals),
observation = 1:nrow(model_data)
) %>%
filter(abs(standardized_residuals) > 3) %>%
dplyr::select(observation)
model_data[potential_outliers$observation, ]
## Create a model without those outliers
no_outlier <- lm(formula = log(n_gibill) ~ log(undergrad_enrollment) + log(avg_yellow_ribbon_payment) +
log(annual_tuition) + poe_member + dodmou + credit_for_mil_training + student_vet_grp_ipeds +
salary_all_students + n_vets_census, data = model_data[-potential_outliers$observation, ])
summary(no_outlier)
plot(no_outlier)
# Final Tables and Visualizations -----------------------------------------
regression_sum_tbl <- selected_model %>%
tbl_regression(
label = list(
"log(undergrad_enrollment)" ~ "Log Undergraduate Enrollment",
"log(avg_yellow_ribbon_payment)" ~ " Log Mean Yellow Ribbon Payment",
"log(annual_tuition)" ~ "Log Annual Tuition",
"n_vets_census" ~ "Veterans in Community From Census",
"log(salary_all_students)" ~ "Log Post-Graduation Salary (All Students)",
"poe_member" ~ "Principles of Excellence Signatory",
"dodmou" ~ "Signed MOU with Department of Defense",
"credit_for_mil_training" ~ "Offers Academic Credit for Military Training",
"student_vet_grp_ipeds" ~ "Has Recognized Student Veteran Group on Campus"
), intercept = TRUE,
show_single_row = c(poe_member, dodmou, credit_for_mil_training, student_vet_grp_ipeds),
estimate_fun = function(x) style_number(x, digits = 4)
) %>%
bold_labels() %>%
modify_header(label = "**Variable**") %>%
add_vif() %>%
add_significance_stars() %>%
modify_caption("**College Characteristics**") %>%
add_glance_source_note(include = c(r.squared, adj.r.squared, p.value)) %>%
as_gt()
# gtsave(data = regression_sum_tbl, filename = "./tables_graphs/regression_summary.png")
